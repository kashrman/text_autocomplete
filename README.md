
Учебный проект по дополнению текстов. В нем обучена нейросеть, которая на основе начала фразы предсказывает её продолжение.

Структура проекта:

text-autocomplete/
├── data/                            # Датасеты
│   ├── raw_dataset.csv              # "сырой" скачанный датасет
│   └── dataset_processed.csv        # "очищенный" датасет
│   ├── train.csv                    # тренировочная выборка
│   ├── val.csv                      # валидационная выборка
│   └── test.csv                     # тестовая выборка
│
├── src/                             # Весь код проекта
│   ├── data_utils.py                # Обработка датасета
|   ├── next_token_dataset.py        # код с torch Dataset'ом 
│   ├── lstm_model.py                # код lstm модели
|   ├── eval_lstm.py                 # замер метрик lstm модели
|   ├── lstm_train.py                # код обучения модели
|   ├── eval_transformer_pipeline.py # код с запуском и замером качества трансформера
│
├── models/                          # веса обученных моделей
|
├── solution.ipynb                   # ноутбук с решением
└── requirements.txt                 # зависимости проекта 
└── README.md                        # описание и выводы

Датасеты и веса созданы, но не добавлены в удаленный репозиторий, так как по заданию он должен быть менее 10 Мб.

Из-за нехватки времени первая версия обучена только на первых 20000 строк. На выделенной виртуалке одна эпоха обучается около часа, а потом где то в конце падает с 'OutOfMemoryError'. Переобучиться с небольшим значением батча (что должно победить OutOfMemoryError) не успел к сроку, но сделаю во вторую итерацию.

#########################
#########################
Выводы 
#########################
#########################
Сами метрики низкие, хотя в примерах допонения осмысленные (преимущественно).

По метрикам на валидации модели сопоставимы: LSTM чуть лучше по ROUGE‑1 (0.0673 vs 0.0655), а distilgpt2 немного лучше по ROUGE‑2 (0.0061 vs 0.0053), то есть различия небольшие. ROUGE оценивает совпадение n‑грамм и не всегда отражает связность текста при открытой генерации.
​
По примерам distilgpt2 заметно чаще генерирует связные и осмысленные продолжения, тогда как LSTM нередко выдаёт повторяющиеся “частотные” слова и менее читаемый текст. Поэтому для продукта лучше рекомендовать distilgpt2 как более качественную “из коробки” модель, а LSTM — как вариант только при жёстких ограничениях по ресурсам и готовности дополнительно тюнить обучение и генерацию.
​
