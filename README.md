
Учебный проект по дополнению текстов. В нем обучена нейросеть, которая на основе начала фразы предсказывает её продолжение.

Структура проекта:

text-autocomplete/

├── data/                            # Датасеты

│   ├── raw_dataset.csv              # "сырой" скачанный датасет

│   └── dataset_processed.csv        # "очищенный" датасет

│   ├── train.csv                    # тренировочная выборка

│   ├── val.csv                      # валидационная выборка

│   └── test.csv                     # тестовая выборка

│

├── src/                             # Весь код проекта

│   ├── data_utils.py                # Обработка датасета

|   ├── next_token_dataset.py        # код с torch Dataset'ом 

│   ├── lstm_model.py                # код lstm модели

|   ├── eval_lstm.py                 # замер метрик lstm модели

|   ├── lstm_train.py                # код обучения модели

|   ├── eval_transformer_pipeline.py # код с запуском и замером качества трансформера

│

├── models/                          # веса обученных моделей

|

├── solution.ipynb                   # ноутбук с решением

└── requirements.txt                 # зависимости проекта 

└── README.md                        # описание и выводы


Датасеты и веса созданы, но не добавлены в удаленный репозиторий, так как он должен быть менее 10 Мб.

#########################

Выводы 

#########################

После обучения на всем датасете получились метрики

LSTM Epoch 8: Train Loss=4.9511, Val Loss=5.0779, ROUGE1-F=0.1071, ROUGE2-F=0.0222 (n=154163)

LSTM VAL: {'rouge1_f': 0.10711065520183888, 'rouge2_f': 0.022228194860246516, 'n_samples': 154163}

GPT2 VAL: {'rouge1_f': 0.05737843178123644, 'rouge2_f': 0.004854144314164569, 'n_samples': 152545}

Сами метрики низкие, хотя в примерах допонения осмысленные (преимущественно).

По метрикам и по примерам лучшей оказалась LSTM: на валидации она существенно превосходит distilgpt2 (ROUGE1-F 0.1071 vs 0.0574, ROUGE2-F 0.0222 vs 0.0049), значит чаще угадывает и отдельные слова, и короткие устойчивые фразы из эталонного продолжения. ROUGE измеряет совпадение n-грамм, поэтому рост ROUGE-2 особенно важен как признак более точного “автодополнения” на коротком горизонте.

По ручным примерам LSTM чаще выдаёт более завершённые и “прикладные” продолжения в формате автодополнения, тогда как distilgpt2 чаще даёт более расплывчатые или не по смыслу продолжения.

Рекомендация: для задачи короткого автодополнения в рамках датасета лучше использовать LSTM, потому что она заметно лучше по метрикам и на примерах даёт более релевантные продолжения. Если нужен “универсальный” генератор более длинного текста вне домена данных, тогда стоит рассматривать distilgpt2, но в текущей постановке явный фаворит — LSTM.
​
